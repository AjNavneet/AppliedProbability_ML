{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Discrete Probability Distributions\n",
        "\n",
        "In machine learning, we use discrete probability distributions to understand and work with random variables. These distributions are vital for various tasks, like binary and multiclass classification, model evaluation, and natural language processing. They even influence decisions in deep learning neural networks.\n",
        "\n",
        "Here's what you'll learn in this tutorial:\n",
        "\n",
        "- **Understanding Discrete Probability Distributions:** Discrete probability distributions help us grasp the likelihood of different outcomes for random variables.\n",
        "\n",
        "- **Bernoulli Distribution:** This distribution describes the probability of a single binary outcome.\n",
        "\n",
        "- **Binomial Distribution:** It's used when you have a sequence of binary outcomes.\n",
        "\n",
        "- **Multinoulli Distribution:** When you deal with a single categorical outcome, the Multinoulli distribution comes into play.\n",
        "\n",
        "- **Multinomial Distribution:** If you're working with sequences of categorical outcomes, the Multinomial distribution is your go-to.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XsIrjEPgrRbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discrete Probability Distributions\n",
        "\n",
        "In the world of probability, we encounter random variables, which are values generated by unpredictable processes. Among these, discrete random variables play a significant role. These variables can only take on a finite set of specific values.\n",
        "\n",
        "## Types of Discrete Random Variables\n",
        "\n",
        "1. **Binary Random Variable:** When a variable can only be 0 or 1, we call it a binary random variable.\n",
        "   \n",
        "2. **Categorical Random Variable:** For a variable that can assume values from 1 to K (where K is the total number of unique outcomes), it's known as a categorical random variable.\n",
        "\n",
        "Each possible outcome of a discrete random variable has an associated probability. The collection of these probabilities is known as a *discrete probability distribution*, often represented by a Probability Mass Function (PMF) or Cumulative Distribution Function (CDF). Here's what you need to know about them:\n",
        "\n",
        "- **PMF (Probability Mass Function):** This function calculates the probability of a specific outcome.\n",
        "\n",
        "- **CDF (Cumulative Distribution Function):** It tells you the probability of a value less than or equal to a given outcome.\n",
        "\n",
        "- **PPF (Percent-Point Function):** The inverse of CDF, which gives you a discrete value less than or equal to a given probability.\n",
        "\n",
        "## Common Discrete Probability Distributions\n",
        "\n",
        "1. **Bernoulli Distribution:** This distribution is ideal for binary random variables.\n",
        "   \n",
        "2. **Binomial Distribution:** When you deal with a sequence of binary random variables, the Binomial distribution is your choice.\n",
        "\n",
        "3. **Multinoulli Distribution:** Use this distribution for categorical random variables.\n",
        "\n",
        "4. **Multinomial Distribution:** For sequences of categorical random variables, the Multinomial distribution is the way to go.\n",
        "\n",
        "These are the most common ones, but there are other interesting distributions to explore, like the Poisson Distribution and the Discrete Uniform Distribution.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Y4h3bN8ArxJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bernoulli Distribution\n",
        "\n",
        "The Bernoulli distribution is a straightforward discrete probability distribution used for situations where the outcome can be either 0 or 1.\n",
        "\n",
        "## Bernoulli Trial\n",
        "\n",
        "Named after the Swiss mathematician Jacob Bernoulli, a Bernoulli trial is an experiment with outcomes following the Bernoulli distribution. Common examples include:\n",
        "\n",
        "- Tossing a coin once (resulting in heads, 0, or tails, 1).\n",
        "- The birth of a child, which could be a boy (0) or a girl (1).\n",
        "\n",
        "In the context of machine learning, a Bernoulli trial could represent binary classification. For instance, classifying a single example as the first class (0) or the second class (1). This distribution can be succinctly described by a single parameter, *p*, which defines the probability of obtaining an outcome of 1. The probabilities for each event are as follows:\n",
        "\n",
        "- Probability of getting 1:  P(x = 1) = p\n",
        "- Probability of getting 0:  P(x = 0) = 1 âˆ’ p\n",
        "\n",
        "For example, when flipping a fair coin, *p* equals 0.5, giving both outcomes an equal probability of 50%.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RZ6W0BWer5_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binomial Distribution\n",
        "\n",
        "The Binomial distribution emerges when we repeatedly perform independent Bernoulli trials, where each trial has only two possible outcomes, either 0 or 1.\n",
        "\n",
        "## Bernoulli Trials\n",
        "\n",
        "A Bernoulli process, named after Jacob Bernoulli, is essentially a series of independent experiments with outcomes following the Bernoulli distribution. Common examples include:\n",
        "\n",
        "- Repeated coin flips, each being an independent trial.\n",
        "- Successive independent births.\n",
        "\n",
        "In the context of machine learning, we can analyze the performance of a binary classification algorithm as a Bernoulli process. The model's prediction on a test example corresponds to a Bernoulli trial (correct or incorrect).\n",
        "\n",
        "The Binomial distribution provides a way to summarize the number of successful outcomes in a given number of Bernoulli trials (*k*), each with a specified success probability (*p*). For example, we can simulate a Bernoulli process with a 30% probability of success (P(x = 1) = 0.3) and a total of 100 trials (k = 100).\n"
      ],
      "metadata": {
        "id": "j5PDKVIpr_MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import binomial\n",
        "\n",
        "# Define the parameters of the distribution\n",
        "p = 0.3\n",
        "k = 100\n",
        "\n",
        "# Run a single simulation\n",
        "success = binomial(k, p)\n",
        "print('Total Success: %d' % success)"
      ],
      "metadata": {
        "id": "CitQmyW8sK5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we run this code, we would expect approximately 30 successful outcomes, given the chosen parameters. However, the specific result may vary with each run.\n",
        "\n",
        "We can calculate the distribution's moments, like the expected value (mean) and variance, using the `binom.stats()` function."
      ],
      "metadata": {
        "id": "HGLKkuFbsNak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "# Define the parameters of the distribution\n",
        "p = 0.3\n",
        "k = 100\n",
        "\n",
        "# Calculate moments\n",
        "mean, var, _, _ = binom.stats(k, p, moments='mvsk')\n",
        "print('Mean=%.3f, Variance=%.3f' % (mean, var))"
      ],
      "metadata": {
        "id": "UDI9AVXWsN-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, the mean (expected value) is 30, and the variance is 21, which yields a standard deviation of approximately 4.5.\n",
        "\n",
        "We can also use the probability mass function to compute the likelihood of achieving different numbers of successful outcomes in a sequence of trials (e.g., 10, 20, 30, to 100)."
      ],
      "metadata": {
        "id": "b2_NLPZAsRE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "# Define the parameters of the distribution\n",
        "p = 0.3\n",
        "k = 100\n",
        "\n",
        "# Define the distribution\n",
        "dist = binom(k, p)\n",
        "\n",
        "# Calculate the probability of n successes\n",
        "for n in range(10, 110, 10):\n",
        "    print('P of %d success: %.3f%%' % (n, dist.pmf(n) * 100))"
      ],
      "metadata": {
        "id": "B-95pMzVsUft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cumulative distribution function (CDF) can help us find the probability of achieving a certain number of successes or fewer."
      ],
      "metadata": {
        "id": "wf9nSSa8saZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom\n",
        "\n",
        "# Define the parameters of the distribution\n",
        "p = 0.3\n",
        "k = 100\n",
        "\n",
        "# Define the distribution\n",
        "dist = binom(k, p)\n",
        "\n",
        "# Calculate the probability of <=n successes\n",
        "for n in range(10, 110, 10):\n",
        "    print('P of %d success: %.3f%%' % (n, dist.cdf(n) * 100))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqzWPxh3sYJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using the CDF, we find that after 50 successes or less, we cover nearly 100% of the expected outcomes in this distribution.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Bg5nOCzssfht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinoulli Distribution\n",
        "\n",
        "The Multinoulli distribution, also known as the categorical distribution, is used when an event can have one of *K* possible outcomes.\n",
        "\n",
        "## Categorical Events\n",
        "\n",
        "This distribution expands upon the concept of the Bernoulli distribution, which applies to binary variables (K = 2). In the Multinoulli distribution, we deal with categorical variables, where *K* can be any positive integer, and each outcome belongs to the set {1, 2, 3, ..., K}. An illustrative example is rolling a six-sided die, where *K* equals 6.\n",
        "\n",
        "In the context of machine learning, a typical application is multiclass classification, where a single example is classified into one of *K* classes. For instance, classifying a species of iris flower into one of three different categories.\n",
        "\n",
        "The Multinoulli distribution is characterized by *p* variables, where *p1* to *pK* represent the probabilities of each categorical outcome from 1 to *K*. Importantly, the probabilities sum up to 1.0.\n",
        "\n",
        "For instance, when rolling a single die, each outcome (1 to 6) has a probability of 1/6 or approximately 16.6%.\n",
        "\n",
        "- P(x = 1) = p1\n",
        "- P(x = 2) = p2\n",
        "- P(x = 3) = p3\n",
        "- ...\n",
        "- P(x = K) = pK\n",
        "\n",
        "This distribution enables us to model and understand the probabilities associated with various categorical outcomes, making it a fundamental tool in multiclass classification and other applications involving discrete, non-binary events.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GWrA2gUmsoq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Distribution\n",
        "\n",
        "The Multinomial distribution comes into play when you repeatedly perform independent Multinoulli trials, representing a generalization of the binomial distribution for a discrete variable with *K* possible outcomes.\n",
        "\n",
        "## Multinoulli Trials\n",
        "\n",
        "A Multinoulli trial refers to an experiment with multiple possible outcomes, and each outcome can fall into one of *K* categories. An example of a multinomial process is a sequence of independent dice rolls. In natural language processing, another common application of the multinomial distribution is to count the occurrences of words in a text document.\n",
        "\n",
        "A Multinomial distribution can be described by a discrete random variable with *K* outcomes, along with probabilities assigned to each outcome (*p1* to *pK*). This distribution is based on *n* successive trials.\n",
        "\n",
        "For instance, let's consider a small example with 3 categories (K = 3), each with an equal probability (p = 33.33%), and 100 trials. You can use the `multinomial()` function from NumPy to simulate 100 independent trials and summarize the number of times each category occurs.\n",
        "\n"
      ],
      "metadata": {
        "id": "o3-yX6issqEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import multinomial\n",
        "\n",
        "# Define the parameters of the distribution\n",
        "p = [1.0/3.0, 1.0/3.0, 1.0/3.0]\n",
        "k = 100\n",
        "\n",
        "# Run a single simulation\n",
        "cases = multinomial(k, p)\n",
        "\n",
        "# Summarize cases\n",
        "for i in range(len(cases)):\n",
        "    print('Case %d: %d' % (i+1, cases[i]))"
      ],
      "metadata": {
        "id": "gTRhAMnlr5NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, each category is expected to have roughly 33 events. However, since it's a random process, the specific results may vary with each run.\n",
        "\n",
        "We can calculate the probability of a specific combination occurring using the probability mass function, which is achieved using the `multinomial.pmf()` function from SciPy."
      ],
      "metadata": {
        "id": "FNFnic78sxYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import multinomial\n",
        "\n",
        "# Define the parameters of the distribution\n",
        "p = [1.0/3.0, 1.0/3.0, 1.0/3.0]\n",
        "k = 100\n",
        "\n",
        "# Define the distribution\n",
        "dist = multinomial(k, p)\n",
        "\n",
        "# Define a specific number of outcomes from 100 trials\n",
        "cases = [33, 33, 34]\n",
        "\n",
        "# Calculate the probability for the case\n",
        "pr = dist.pmf(cases)\n",
        "\n",
        "# Print as a percentage\n",
        "print('Case=%s, Probability: %.3f%%' % (cases, pr*100))"
      ],
      "metadata": {
        "id": "hH624-AVszbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running this code provides the probability of less than 1% for the idealized number of cases [33, 33, 34] for each event type. The specific results will vary with each run due to the inherent randomness of the process.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6kcOh4ts2OQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Reading\n",
        "\n",
        "## Books\n",
        "\n",
        "1. [Pattern Recognition and Machine Learning (2006)](https://amzn.to/2JwHE7I)\n",
        "   - Chapter 2: Probability Distributions\n",
        "\n",
        "2. [Deep Learning (2016)](https://amzn.to/2lnc3vL)\n",
        "   - Section 3.9: Common Probability Distributions\n",
        "\n",
        "3. [Machine Learning: A Probabilistic Perspective (2012)](https://amzn.to/2xKSTCP)\n",
        "   - Section 2.3: Some common discrete distributions\n",
        "\n",
        "## API Documentation\n",
        "\n",
        "- [Discrete Statistical Distributions, SciPy](https://docs.scipy.org/doc/scipy/reference/tutorial/stats/discrete.html)\n",
        "\n",
        "- [scipy.stats.bernoulli API](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bernoulli.html)\n",
        "\n",
        "- [scipy.stats.binom API](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html)\n",
        "\n",
        "- [scipy.stats.multinomial API](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multinomial.html)\n",
        "\n",
        "## Articles\n",
        "\n",
        "- [Bernoulli distribution, Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n",
        "\n",
        "- [Bernoulli process, Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_process)\n",
        "\n",
        "- [Bernoulli trial, Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_trial)\n",
        "\n",
        "- [Binomial distribution, Wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution)\n",
        "\n",
        "- [Categorical distribution, Wikipedia](https://en.wikipedia.org/wiki/Categorical_distribution)\n",
        "\n",
        "- [Multinomial distribution, Wikipedia](https://en.wikipedia.org/wiki/Multinomial_distribution)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "e6h5DfuYtCA8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wx2OZvnSs5mP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}